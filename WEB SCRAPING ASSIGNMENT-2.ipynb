{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPING ASSIGNMENT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q1: Write a python program to scrape data for “Data Analyst” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore”in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C://Users//Friday//chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria\n",
    "search_job = driver.find_element_by_xpath(\"//div[@class = 'inpWrap']/input[@id='qsb-keyword-sugg']\")\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "search_loc = driver.find_element_by_xpath(\"//div[@class = 'inpWrap']/input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Banglore\")\n",
    "search_btn = driver.find_element_by_xpath(\"//div[@class = 'search-btn']//button[@class = 'btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXEPERIENCE</th>\n",
       "      <th>JOB</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-2 Yrs</td>\n",
       "      <td>Market Unit - Data Business Analyst (11)</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Data Analyst Analyzing</td>\n",
       "      <td>Cistup Indian Institute of Science</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Analyst-Finance Data Maintenance</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Analyst-Data Management</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Senior Analyst-Data Visualization</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Senior Analyst-Data Management</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Senior Analyst-Data Management</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Senior Analyst-Data Visualization</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Senior Analyst-Finance Data Maintenance</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EXEPERIENCE                                       JOB  \\\n",
       "2     1-2 Yrs  Market Unit - Data Business Analyst (11)   \n",
       "0     2-5 Yrs                    Data Analyst Analyzing   \n",
       "4     3-5 Yrs          Analyst-Finance Data Maintenance   \n",
       "6     3-5 Yrs                   Analyst-Data Management   \n",
       "3     3-6 Yrs                              Data Analyst   \n",
       "1     5-8 Yrs         Senior Analyst-Data Visualization   \n",
       "5     5-8 Yrs            Senior Analyst-Data Management   \n",
       "7     5-8 Yrs            Senior Analyst-Data Management   \n",
       "8     5-8 Yrs         Senior Analyst-Data Visualization   \n",
       "9     5-8 Yrs   Senior Analyst-Finance Data Maintenance   \n",
       "\n",
       "                              COMPANY         SALARY             LOCATION  \n",
       "2         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "0  Cistup Indian Institute of Science  Not disclosed  Bangalore/Bengaluru  \n",
       "4         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "6         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "3            Myntra Designs Pvt. Ltd.  Not disclosed  Bangalore/Bengaluru  \n",
       "1         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "5         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "7         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "8         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "9         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = []# name of the job\n",
    "company_name = []# name of the company\n",
    "exp = []# experience as per post\n",
    "salary = []# salary as per advert\n",
    "loc = []#Location as per advert\n",
    "\n",
    "time.sleep(5) #am setting time as 5 since it takes more time to load the page\n",
    "\n",
    "#sorting the required information and storing in the list.\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'title fw500 ellipsis']\")[:10]:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'subTitle ellipsis fleft']\")[:10]:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi location']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    loc.append(i.text)        \n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi experience']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    exp.append(i.text)\n",
    "        \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi salary']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    salary.append(i.text)\n",
    "    \n",
    "driver.quit()#exiting the driver post scraping the information\n",
    "\n",
    "#storing the data in a DataFrame.\n",
    "Data_Analyst_jobs_Banglore = pd.DataFrame({ \"EXEPERIENCE\": exp, \"JOB\" : job_title ,\"COMPANY\": company_name ,\n",
    "                                           \"SALARY\" : salary,\"LOCATION\" :loc})\n",
    "                                           \n",
    "Data_Analyst_jobs_Banglore.sort_values(by = [\"EXEPERIENCE\"])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- 1. All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C://Users//Friday//chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "search_job = driver.find_element_by_xpath(\"//div[@class = 'inpWrap']/input[@id='qsb-keyword-sugg']\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "search_loc = driver.find_element_by_xpath(\"//div[@class = 'inpWrap']/input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Banglore\")\n",
    "search_btn = driver.find_element_by_xpath(\"//div[@class = 'search-btn']//button[@class = 'btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []#title of job\n",
    "company_name = []#name of company\n",
    "exp = []#Exeperience Required as per job advert\n",
    "salary = []#Salary offered by company\n",
    "loc = []#Location as per advert\n",
    "item = []# Dummy list to store hyperlink of each advert\n",
    "skill = [] #Skill(s) required for the job opening\n",
    "skills= []#Skill(s) required for the job opening\n",
    "des = []# description of the job\n",
    "date = [] #Date of post\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#sorting the required information and storing in the list.\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'title fw500 ellipsis']\")[:10]:\n",
    "    job_title.append(i.text)\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'subTitle ellipsis fleft']\")[:10]:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi experience']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    exp.append(i.text)\n",
    "        \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi salary']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    salary.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi location']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    loc.append(i.text)    \n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'title fw500 ellipsis']\")[:10]:\n",
    "    item.append(i.get_attribute('href'))\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'type br2 fleft grey']//span[@class = 'fleft fw500']\")[:10]:\n",
    "    date.append(i.text)       \n",
    "\n",
    "driver.quit()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting all job description by entering into every job advert.\n",
    "for i in item:\n",
    "    driver = webdriver.Chrome(r\"C://Users//Friday//chromedriver.exe\")\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    DES = driver.find_elements_by_xpath(\"//section[@class = 'JD av_textblock_section']/div[@class = 'nConfig_textblock ']/div[@class = 'clearboth description']\") \\\n",
    "    or driver.find_elements_by_xpath(\"//section[@class = 'job-desc']/div[@class = 'dang-inner-html']\")\n",
    "    \n",
    "    for i in DES:\n",
    "        des.append(i.text.replace(\"\\n\",\"\")) \n",
    "\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class = 'key-skill']/div\"):\n",
    "        skill.append(i.text)\n",
    "        skill = [' '.join(skill)]       \n",
    " \n",
    "    driver.close()\n",
    "\n",
    "for i in skill:\n",
    "    skills.append(i.split(\"Key Skills\"))\n",
    "skills= skills[0]\n",
    "skills.remove(\"\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXPERIENCE_REQ</th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>REQ_SKILLS</th>\n",
       "      <th>SALARY_OFFERED</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>JD</th>\n",
       "      <th>POST_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-1 Yrs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CronJ IT Technologies Private Limited</td>\n",
       "      <td>TensorflowJavaC++CphythonData StructuresArtif...</td>\n",
       "      <td>3,50,000 - 5,00,000 PA.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Responsibilities and DutiesCreate innovative s...</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-1 Yrs</td>\n",
       "      <td>Opportunity For Data Scientist Internship - Be...</td>\n",
       "      <td>Corner Stone Solutions</td>\n",
       "      <td>NLPOpencvArtificial Intelligence Data Science...</td>\n",
       "      <td>1,00,000 - 3,00,000 PA.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Location - Bangalore / BengaluruDuration- 6 Mo...</td>\n",
       "      <td>10 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>HiveRCloud ComputingData ScientistComputer Vi...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Roles and Responsibilities- Selecting features...</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>TensorflowObject DetectionAlgorithm Developme...</td>\n",
       "      <td>7,00,000 - 15,00,000 PA.</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Roles and ResponsibilitiesMust have strong Pyt...</td>\n",
       "      <td>10 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Associate Data Scientist - CRM &amp; Loyalty</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>Direct MarketingMultivariate AnalysisR Data S...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>The RoleGeneral Position DefinitionThis role w...</td>\n",
       "      <td>29 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Data Scientist/Senior Data Scientist</td>\n",
       "      <td>GANIT BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Predictive ModelingManufacturing AnalyticsPyt...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>About Ganit IncFounded by senior industry expe...</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Data Scientist/ Analyst</td>\n",
       "      <td>Becton Dickinson India Pvt. Ltd</td>\n",
       "      <td>RHiveHadoopData AnalyticsMachine LearningPyth...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Roles and Responsibilitiesob Description Summa...</td>\n",
       "      <td>12 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Global Medical Data Scientist</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>SQL DatabricksText AnalyticsArtificial Intell...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>This is an ideal role for an experienced candi...</td>\n",
       "      <td>2 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>DBCG IND - GAMMA Senior Data Scientist</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Computer scienceadvanced analyticsSDSdata sci...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>What Youll DoWe re looking for a passionat...</td>\n",
       "      <td>5 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Data Scientist || Data Analyst || Data science</td>\n",
       "      <td>Inspiration Manpower Consultancy Pvt. Ltd.</td>\n",
       "      <td>Data ScienceJavaREDAStatistical ModelingData ...</td>\n",
       "      <td>14,00,000 - 22,50,000 PA.</td>\n",
       "      <td>Navi Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Job descriptionJob Summary and Key Responsibil...</td>\n",
       "      <td>9 DAYS AGO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EXPERIENCE_REQ                                          JOB_TITLE  \\\n",
       "0        0-1 Yrs                                     Data Scientist   \n",
       "1        0-1 Yrs  Opportunity For Data Scientist Internship - Be...   \n",
       "3        2-5 Yrs                  Data Scientist - Machine Learning   \n",
       "7        2-7 Yrs  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "9        3-5 Yrs           Associate Data Scientist - CRM & Loyalty   \n",
       "6        4-8 Yrs               Data Scientist/Senior Data Scientist   \n",
       "2       5-10 Yrs                            Data Scientist/ Analyst   \n",
       "8       5-10 Yrs                      Global Medical Data Scientist   \n",
       "5       6-10 Yrs             DBCG IND - GAMMA Senior Data Scientist   \n",
       "4       6-11 Yrs     Data Scientist || Data Analyst || Data science   \n",
       "\n",
       "                                 COMPANY_NAME  \\\n",
       "0       CronJ IT Technologies Private Limited   \n",
       "1                      Corner Stone Solutions   \n",
       "3                                 AugmatrixGo   \n",
       "7                                    CES Ltd.   \n",
       "9         Shell India Markets Private Limited   \n",
       "6    GANIT BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "2             Becton Dickinson India Pvt. Ltd   \n",
       "8     GlaxoSmithKline Pharmaceuticals Limited   \n",
       "5                     Boston Consulting Group   \n",
       "4  Inspiration Manpower Consultancy Pvt. Ltd.   \n",
       "\n",
       "                                          REQ_SKILLS  \\\n",
       "0   TensorflowJavaC++CphythonData StructuresArtif...   \n",
       "1   NLPOpencvArtificial Intelligence Data Science...   \n",
       "3   HiveRCloud ComputingData ScientistComputer Vi...   \n",
       "7   TensorflowObject DetectionAlgorithm Developme...   \n",
       "9   Direct MarketingMultivariate AnalysisR Data S...   \n",
       "6   Predictive ModelingManufacturing AnalyticsPyt...   \n",
       "2   RHiveHadoopData AnalyticsMachine LearningPyth...   \n",
       "8   SQL DatabricksText AnalyticsArtificial Intell...   \n",
       "5   Computer scienceadvanced analyticsSDSdata sci...   \n",
       "4   Data ScienceJavaREDAStatistical ModelingData ...   \n",
       "\n",
       "              SALARY_OFFERED  \\\n",
       "0    3,50,000 - 5,00,000 PA.   \n",
       "1    1,00,000 - 3,00,000 PA.   \n",
       "3              Not disclosed   \n",
       "7   7,00,000 - 15,00,000 PA.   \n",
       "9              Not disclosed   \n",
       "6              Not disclosed   \n",
       "2              Not disclosed   \n",
       "8              Not disclosed   \n",
       "5              Not disclosed   \n",
       "4  14,00,000 - 22,50,000 PA.   \n",
       "\n",
       "                                            LOCATION  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "7  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "6  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "5    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "4                   Navi Mumbai, Bangalore/Bengaluru   \n",
       "\n",
       "                                                  JD    POST_DATE  \n",
       "0  Responsibilities and DutiesCreate innovative s...   3 DAYS AGO  \n",
       "1  Location - Bangalore / BengaluruDuration- 6 Mo...  10 DAYS AGO  \n",
       "3  Roles and Responsibilities- Selecting features...   3 DAYS AGO  \n",
       "7  Roles and ResponsibilitiesMust have strong Pyt...  10 DAYS AGO  \n",
       "9  The RoleGeneral Position DefinitionThis role w...  29 DAYS AGO  \n",
       "6  About Ganit IncFounded by senior industry expe...   3 DAYS AGO  \n",
       "2  Roles and Responsibilitiesob Description Summa...  12 DAYS AGO  \n",
       "8  This is an ideal role for an experienced candi...   2 DAYS AGO  \n",
       "5      What Youll DoWe re looking for a passionat...   5 DAYS AGO  \n",
       "4  Job descriptionJob Summary and Key Responsibil...   9 DAYS AGO  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Storing our data into Data Frame.\n",
    "DataScientist_jobs_Banglore = pd.DataFrame({\"EXPERIENCE_REQ\" : exp, \n",
    "                                            \"JOB_TITLE\" : job_title,\n",
    "                                            \"COMPANY_NAME\" : company_name,\n",
    "                                            \"REQ_SKILLS\" : skills,\n",
    "                                            \"SALARY_OFFERED\" : salary, \n",
    "                                            \"LOCATION\" : loc,\n",
    "                                            \"JD\" : des,\n",
    "                                            \"POST_DATE\" : date\n",
    "                                           })\n",
    "                                           \n",
    "DataScientist_jobs_Banglore.sort_values(by = [\"EXPERIENCE_REQ\"]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXEPERIENCE_REQ</th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>POST_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>30+ DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Msg.ai</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>30+ DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>itForte Staffing Services Private Ltd.</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>30+ DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Data Scientist | Python | Machine Learning | D...</td>\n",
       "      <td>Careerera</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>4,75,000 - 9,75,000 PA.</td>\n",
       "      <td>9 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>9 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>9 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Data Scientist/Data Analyst - Python/Machine L...</td>\n",
       "      <td>Change leaders</td>\n",
       "      <td>Mumbai, Ghaziabad</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>10 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>GCP Presales AIML Architect &amp; Data Scientist (...</td>\n",
       "      <td>Lecan Solutions Pvt Ltd</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>10 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>GCP Presales AIML Architect &amp; Data Scientist (...</td>\n",
       "      <td>Lecan Solutions Pvt Ltd</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>10 DAYS AGO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EXEPERIENCE_REQ                                          JOB_TITLE  \\\n",
       "9         1-3 Yrs                    Data Scientist Machine Learning   \n",
       "2         3-5 Yrs                                     Data Scientist   \n",
       "1         3-8 Yrs                                     Data Scientist   \n",
       "5         3-8 Yrs  Data Scientist | Python | Machine Learning | D...   \n",
       "0         4-8 Yrs                                     Data Scientist   \n",
       "3         4-8 Yrs                                     Data Scientist   \n",
       "4         4-8 Yrs                                     Data Scientist   \n",
       "6        5-10 Yrs  Data Scientist/Data Analyst - Python/Machine L...   \n",
       "7        6-11 Yrs  GCP Presales AIML Architect & Data Scientist (...   \n",
       "8        6-11 Yrs  GCP Presales AIML Architect & Data Scientist (...   \n",
       "\n",
       "                             COMPANY_NAME                LOCATION  \\\n",
       "9                               Delhivery        Gurgaon/Gurugram   \n",
       "2                                  Msg.ai        Gurgaon/Gurugram   \n",
       "1  itForte Staffing Services Private Ltd.        Gurgaon/Gurugram   \n",
       "5                               Careerera  Noida(Sector-59 Noida)   \n",
       "0                           NatWest Group             Delhi / NCR   \n",
       "3                           NatWest Group        Gurgaon/Gurugram   \n",
       "4                           NatWest Group             Delhi / NCR   \n",
       "6                          Change leaders       Mumbai, Ghaziabad   \n",
       "7                 Lecan Solutions Pvt Ltd                   Noida   \n",
       "8                 Lecan Solutions Pvt Ltd                   Noida   \n",
       "\n",
       "                    SALARY     POST_DATE  \n",
       "9            Not disclosed  30+ DAYS AGO  \n",
       "2            Not disclosed  30+ DAYS AGO  \n",
       "1            Not disclosed  30+ DAYS AGO  \n",
       "5  4,75,000 - 9,75,000 PA.    9 DAYS AGO  \n",
       "0            Not disclosed    3 DAYS AGO  \n",
       "3            Not disclosed    9 DAYS AGO  \n",
       "4            Not disclosed    9 DAYS AGO  \n",
       "6            Not disclosed   10 DAYS AGO  \n",
       "7            Not disclosed   10 DAYS AGO  \n",
       "8            Not disclosed   10 DAYS AGO  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C://Users//Friday//chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "search_job = driver.find_element_by_xpath(\"//div[@class = 'inpWrap']/input[@id='qsb-keyword-sugg']\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "search_btn = driver.find_element_by_xpath(\"//div[@class = 'search-btn']//button[@class = 'btn']\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(3)\n",
    "#Clicking the filter required.\n",
    "Filter1 = driver.find_element_by_xpath(\"//label[@for='chk-Delhi / NCR-cityTypeGid-']/i\")\n",
    "Filter1.click()\n",
    "time.sleep(3)\n",
    "#Clicking the filter required.\n",
    "Filter2 = driver.find_element_by_xpath(\"//label[@for='chk-3-6 Lakhs-ctcFilter-']/i\")\n",
    "Filter2.click()\n",
    "\n",
    "job_title = []#title of job\n",
    "company_name = []#title of Company\n",
    "exp = []#Experience req\n",
    "salary = []# Salary offered\n",
    "date = []# Date of post\n",
    "loc = []#Location of the job\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#sorting the required information and storing in the list.\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'title fw500 ellipsis']\")[:10]:\n",
    "    job_title.append(i.text)\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'subTitle ellipsis fleft']\")[:10]:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi experience']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    exp.append(i.text)\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi location']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    loc.append(i.text)        \n",
    "        \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi salary']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    salary.append(i.text)\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'type br2 fleft grey']//span[@class = 'fleft fw500']\")[:10]:\n",
    "    date.append(i.text)       \n",
    "    \n",
    "    \n",
    "driver.quit()\n",
    "\n",
    "#storing all the required information into DataFrame.\n",
    "\n",
    "DataScientist_JOBDelhi= pd.DataFrame({ \"EXEPERIENCE_REQ\": exp, \"JOB_TITLE\" : job_title ,\"COMPANY_NAME\": company_name , \n",
    "                                           \"LOCATION\" : loc,\n",
    "                                           \"SALARY\" : salary,\n",
    "                                          \"POST_DATE\" : date})\n",
    "                                           \n",
    "DataScientist_JOBDelhi.sort_values(by = [\"EXEPERIENCE_REQ\"])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C://Users//Friday//chromedriver.exe\")\n",
    "driver.get(\"https://www.glassdoor.co.in/index.htm\")\n",
    "driver.maximize_window()\n",
    "\n",
    "#signing in with userid and password.\n",
    "time.sleep(5)\n",
    "signin_btn = driver.find_element_by_xpath(\"//div[@class = 'locked-home-sign-in']//a\")\n",
    "signin_btn.click()\n",
    "\n",
    "time.sleep(1)\n",
    "user_id = driver.find_element_by_xpath(\"//div[@class = 'input-wrapper css-q444d9']/input[@id='userEmail']\")\n",
    "user_id.send_keys(\"dkdemons@gmail.com\")\n",
    "\n",
    "passwords = driver.find_element_by_xpath(\"//div[@class = 'input-wrapper css-q444d9']/input[@id='userPassword']\")\n",
    "passwords.send_keys(\"Dilip@2021\")\n",
    "\n",
    "sub_button = driver.find_element_by_xpath(\"//button[@class = 'gd-ui-button minWidthBtn css-8i7bc2']\")\n",
    "sub_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>Job_posting_date</th>\n",
       "      <th>Ratting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elsevier</td>\n",
       "      <td>9d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>4d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>25d</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>2d</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>4d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>23d</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WishFin</td>\n",
       "      <td>6d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Srijan Technologies Pvt Ltd</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abc consultants</td>\n",
       "      <td>24d</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>7d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company_name Job_posting_date Ratting\n",
       "0                      Elsevier               9d     4.3\n",
       "1            Ericsson-Worldwide               4d     4.1\n",
       "2                         Adobe              25d     4.4\n",
       "3                      Techlive               2d     5.0\n",
       "4                Biz2Credit Inc               4d     3.8\n",
       "5          Gauge Data Solutions              23d     3.1\n",
       "6                       WishFin               6d     3.8\n",
       "7   Srijan Technologies Pvt Ltd              24h     3.9\n",
       "8               abc consultants              24d     4.2\n",
       "9  Salasar New Age Technologies               7d     3.7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entering the required details in search certeria.\n",
    "time.sleep(3)\n",
    "job_ser = driver.find_element_by_xpath(\"//div[@class = 'input-wrapper css-q444d9']/input[@id='sc.keyword']\")\n",
    "job_ser.send_keys(\"Data Scientist\")\n",
    "\n",
    "loc_ser = driver.find_element_by_xpath(\"//div[@class = 'input-wrapper css-q444d9']/input[@id='sc.location']\")\n",
    "loc_ser.send_keys(\"Noida\")\n",
    "\n",
    "search_button = driver.find_element_by_xpath(\"//button[@class = 'gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "search_button.click()\n",
    "\n",
    "company_name =[] #Name of the company\n",
    "Job_posting_date = [] #No.of days before job posted\n",
    "Ratting = []# Ratting of the Company\n",
    "\n",
    "#sorting the required information and storing in the list.\n",
    "time.sleep(3)\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'd-flex justify-content-between align-items-start']/a[@class = ' css-l2wjgv e1n63ojh0 jobLink']/span\")[:10]:\n",
    "    company_name.append(i.text)\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'd-flex align-items-end pl-std css-mi55ob']\")[:10]:\n",
    "    Job_posting_date.append(i.text)\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'd-flex flex-column css-x75kgh e1rrn5ka3']//span[@class = 'css-19pjha7 e1cjmv6j1']\")[:10]:\n",
    "    Ratting.append(i.text)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "#Creating Data frame with the collected data\n",
    "DataScientist_JOBNoida= pd.DataFrame({ \"company_name\": company_name,\n",
    "                                      \"Job_posting_date\" : Job_posting_date,\n",
    "                                      \"Ratting\": Ratting})\n",
    "DataScientist_JOBNoida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6. Store the data in a dataframe.\n",
    "\n",
    "Note that all of the above steps have to be done by coding only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C://Users//Friday//chromedriver.exe\")\n",
    "driver.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")\n",
    "driver.maximize_window()\n",
    "\n",
    "time.sleep(3)\n",
    "job_ser = driver.find_element_by_xpath(\"//input[@class='keyword']\")\n",
    "job_ser.send_keys(\"Data Scientist\")\n",
    "\n",
    "loc_ser = driver.find_element_by_xpath(\"//input[@id='LocationSearch']\")\n",
    "loc_ser.clear()\n",
    "loc_ser.send_keys(\"Noida\")\n",
    "\n",
    "sub_button = driver.find_element_by_xpath(\"//button[@class = 'gd-btn-mkt']\")\n",
    "sub_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>Average_salary</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹336L</td>\n",
       "      <td>₹1,080L</td>\n",
       "      <td>₹ 6,01,000/yr</td>\n",
       "      <td>14 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹579L</td>\n",
       "      <td>₹2,222L</td>\n",
       "      <td>₹ 11,51,207/yr</td>\n",
       "      <td>14 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹452L</td>\n",
       "      <td>₹11,669L</td>\n",
       "      <td>₹ 12,34,207/yr</td>\n",
       "      <td>14 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹589L</td>\n",
       "      <td>₹2,741L</td>\n",
       "      <td>₹ 7,63,825/yr</td>\n",
       "      <td>13 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹350L</td>\n",
       "      <td>₹1,619L</td>\n",
       "      <td>₹ 7,32,209/yr</td>\n",
       "      <td>12 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹1,050L</td>\n",
       "      <td>₹1,500L</td>\n",
       "      <td>₹ 13,88,910/yr</td>\n",
       "      <td>10 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹504L</td>\n",
       "      <td>₹1,471L</td>\n",
       "      <td>₹ 8,18,515/yr</td>\n",
       "      <td>9 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>₹623L</td>\n",
       "      <td>₹1,702L</td>\n",
       "      <td>₹ 12,01,403/yr</td>\n",
       "      <td>8 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹203L</td>\n",
       "      <td>₹1,817L</td>\n",
       "      <td>₹ 10,00,000/yr</td>\n",
       "      <td>7 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹578L</td>\n",
       "      <td>₹1,500L</td>\n",
       "      <td>₹ 11,90,000/yr</td>\n",
       "      <td>7 salaries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                company_name min_salary max_salary  Average_salary  \\\n",
       "0  Tata Consultancy Services      ₹336L    ₹1,080L   ₹ 6,01,000/yr   \n",
       "1                  Accenture      ₹579L    ₹2,222L  ₹ 11,51,207/yr   \n",
       "2                  Delhivery      ₹452L   ₹11,669L  ₹ 12,34,207/yr   \n",
       "3                        IBM      ₹589L    ₹2,741L   ₹ 7,63,825/yr   \n",
       "4         Ericsson-Worldwide      ₹350L    ₹1,619L   ₹ 7,32,209/yr   \n",
       "5         UnitedHealth Group    ₹1,050L    ₹1,500L  ₹ 13,88,910/yr   \n",
       "6         Valiance Solutions      ₹504L    ₹1,471L   ₹ 8,18,515/yr   \n",
       "7                 Innovaccer      ₹623L    ₹1,702L  ₹ 12,01,403/yr   \n",
       "8              ZS Associates      ₹203L    ₹1,817L  ₹ 10,00,000/yr   \n",
       "9                EXL Service      ₹578L    ₹1,500L  ₹ 11,90,000/yr   \n",
       "\n",
       "        rating  \n",
       "0  14 salaries  \n",
       "1  14 salaries  \n",
       "2  14 salaries  \n",
       "3  13 salaries  \n",
       "4  12 salaries  \n",
       "5  10 salaries  \n",
       "6   9 salaries  \n",
       "7   8 salaries  \n",
       "8   7 salaries  \n",
       "9   7 salaries  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting the required information and storing in the list.\n",
    "min_salary,max_salary,company_name, Average_salary,rating= [],[],[],[],[]\n",
    "total_sal = []\n",
    "time.sleep(3)\n",
    "for i in driver.find_elements_by_xpath(\"//div[@data-test= 'job-info']//p[@class = 'm-0 ']\")[:10]:\n",
    "    company_name.append(i.text)\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'common__RangeBarStyle__values d-flex justify-content-between ']\")[:10]:\n",
    "    total_sal.append(i.text)\n",
    "min_salary= [i.split('\\n')[0] for i in total_sal]\n",
    "max_salary= [i.split('\\n')[1] for i in total_sal]    \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'col-2 d-none d-md-flex flex-row justify-content-end']\")[:10]:\n",
    "    Average_salary.append(i.text.replace('\\n',''))\n",
    "for i in driver.find_elements_by_xpath(\"//p[@class = 'css-1uyte9r css-1kuy7z7 m-0 ']\")[:10]:\n",
    "    rating.append(i.text.replace('\\n',''))\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "#Creating DataFrame with the collected details.\n",
    "DataScientist_AVGSalary=pd.DataFrame({\"company_name\" : company_name,\n",
    "                                      \"min_salary\" : min_salary,\n",
    "                                      \"max_salary\" : max_salary,\n",
    "                                      \"Average_salary\" : Average_salary,\n",
    "                                      \"rating\" :rating})\n",
    "\n",
    "DataScientist_AVGSalary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    ">To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses.\n",
    "\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C://Users//Friday//chromedriver.exe\")\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "driver.maximize_window()\n",
    "\n",
    "#closing the login Pop-up\n",
    "time.sleep(3)\n",
    "pop_up = driver.find_element_by_xpath(\"//div[@class='_2QfC02']/button[@class = '_2KpZ6l _2doB4z']\")\n",
    "pop_up.click()\n",
    "\n",
    "prod_ser = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']//input[@type = 'text']\")\n",
    "prod_ser.send_keys(\"sunglasses\")\n",
    "\n",
    "sub_button = driver.find_element_by_xpath(\"//div[@class = 'col-12-12 _2oO9oE']//button[@class = 'L0Z3Pu']\")\n",
    "sub_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting the required information and storing in the list.\n",
    "Brand = []\n",
    "Product_Description= []\n",
    "Price = []\n",
    "Discount =[]\n",
    "\n",
    "while True:\n",
    "    \n",
    "    time.sleep(3)\n",
    "        \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_2B099V']//div[@class = '_2WkVRV']\"):\n",
    "        Brand.append(i.text)\n",
    "        if len(Brand) == 100:\n",
    "            break\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_2B099V']//a\"):\n",
    "        Product_Description.append(i.get_attribute('title'))\n",
    "        if len(Product_Description) == 200:\n",
    "            break\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_25b18c']//div[@class = '_30jeq3']\"):\n",
    "        Price.append(i.text) \n",
    "        if len(Price) == 100:\n",
    "            break    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_3Ay6Sb']/span\"):\n",
    "        Discount.append(i.text)\n",
    "        if len(Discount) == 100:\n",
    "            break  \n",
    "            \n",
    "    if len(Discount) == 100:\n",
    "        break\n",
    "        \n",
    "    for j in driver.find_elements_by_xpath(\"//nav[@class ='yFHi8N']/a[@class = '_1LKTO3']\"):\n",
    "        next=[j.get_attribute(\"href\")]\n",
    "    \n",
    "    time.sleep(3)\n",
    "        \n",
    "    for n in next:\n",
    "        driver.get(n) \n",
    "    \n",
    "driver.close() \n",
    "\n",
    "Product = [] # Since Product_Description have many unwanted information am following this method to clense it.\n",
    "for i in range(0,len(Product_Description)):\n",
    "    if i == 0 or  i/2 == i//2:\n",
    "        Product.append(Product_Description[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Wayfarer Su...</td>\n",
       "      <td>₹574</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAMIW COLLECTION</td>\n",
       "      <td>UV Protection Round Sunglasses (53)</td>\n",
       "      <td>₹189</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹666</td>\n",
       "      <td>16% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Mirrored Sports Sunglasses (73)</td>\n",
       "      <td>₹367</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Badfella</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>₹269</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹759</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹197</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                                Product_Description Price  \\\n",
       "0             Aislin  UV Protection, Gradient Butterfly, Wayfarer Su...  ₹574   \n",
       "1   HAMIW COLLECTION                UV Protection Round Sunglasses (53)  ₹189   \n",
       "2           Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹758   \n",
       "3           Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹666   \n",
       "4           Fastrack  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹499   \n",
       "..               ...                                                ...   ...   \n",
       "95             NuVew     UV Protection, Mirrored Sports Sunglasses (73)  ₹367   \n",
       "96          Badfella  Polarized, UV Protection Retro Square Sunglass...  ₹269   \n",
       "97          Fastrack  UV Protection, Polarized Wayfarer Sunglasses (56)  ₹759   \n",
       "98            PIRASO              UV Protection Aviator Sunglasses (54)  ₹197   \n",
       "99    ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...  ₹499   \n",
       "\n",
       "   Discount  \n",
       "0   62% off  \n",
       "1   88% off  \n",
       "2   15% off  \n",
       "3   16% off  \n",
       "4   50% off  \n",
       "..      ...  \n",
       "95  70% off  \n",
       "96  73% off  \n",
       "97  15% off  \n",
       "98  87% off  \n",
       "99  77% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame.\n",
    "Flipkart_Sunglass = pd.DataFrame({\"Brand\": Brand, \n",
    "                                  \"Product_Description\": Product, \n",
    "                                  \"Price\": Price , \n",
    "                                  \"Discount\": Discount})\n",
    "Flipkart_Sunglass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    " When you will open the above link you will reach to the below shown webpage.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C://Users//Friday//chromedriver.exe\")\n",
    "driver.get(\" https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\")\n",
    "driver.maximize_window()\n",
    "\n",
    "#seeing all the reviews\n",
    "All_rev = driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']/span\")\n",
    "All_rev.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting the required information and storing in the list.\n",
    "Rating = []\n",
    "Review_summary = []\n",
    "Full_review = []\n",
    "\n",
    "while True:\n",
    "    time.sleep(3)\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class = 'col _2wzgFH K0kLPL']/div[@class= 'row']/div\"):\n",
    "        Rating.append(i.text)\n",
    "        if len(Rating) == 200:\n",
    "            break \n",
    "            \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= 'row']//p[@class = '_2-N8zT']\"):\n",
    "        Review_summary.append(i.text)\n",
    "        if len(Review_summary) == 100:\n",
    "            break \n",
    "            \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= 't-ZTKy']//div[@class]\"):\n",
    "        Full_review.append(i.text.replace('\\n',''))\n",
    "        if len(Full_review) == 100:\n",
    "            break \n",
    "        \n",
    "    if len(Full_review) == 100:\n",
    "        break    \n",
    "                \n",
    "    for i in driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']//a[@class='_1LKTO3']\"):\n",
    "        next=[i.get_attribute(\"href\")]\n",
    "    \n",
    "    time.sleep(3)\n",
    "        \n",
    "    for n in next:\n",
    "        driver.get(n)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "Rat = [] # Since Product_Description have many unwanted information am following this method to clense it.\n",
    "for i in range(0,len(Rating)):\n",
    "    if i == 0 or  i/2 == i//2:\n",
    "        Rat.append(Rating[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the MoneyThe iPhone 11 offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.I’m am ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️Its awesome mobile phone in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>*Review after 10 months of usage*Doesn't seem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Excellent camera, good performance, no lag. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It’s been almost a month since I have been usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Awesome Phone. Slightly high price but worth. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Really worth of money. i just love it. It is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>I have migrated from OP 7pro... and trust me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Upgraded from iphone 6 to 11 best phone for ip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is my first ever I phone. Before this I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>It’s an amazing product from apple and the cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>This will help you more. See if you are planni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Well you all know the specifications . One of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>The built quality is not very premium.The batt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really good actually this is my first apple pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>it is very good at performance. Camera is best...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>Very poor</td>\n",
       "      <td>Reviewing again after 5 months. At the beginni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>I can say I'm damn impressed with iPhone 11. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Best Quality Product OF iPhone Series , Sound ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>First thanks to Flipkart for this amazing deal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>I just directly switch from iphone 6s to iphon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Review_summary  \\\n",
       "0       5              Brilliant   \n",
       "1       5       Perfect product!   \n",
       "2       5      Worth every penny   \n",
       "3       5          Great product   \n",
       "4       5     Highly recommended   \n",
       "5       5       Perfect product!   \n",
       "6       5       Perfect product!   \n",
       "7       5              Fabulous!   \n",
       "8       5              Wonderful   \n",
       "9       5      Worth every penny   \n",
       "10      5         Simply awesome   \n",
       "11      5      Worth every penny   \n",
       "12      5       Perfect product!   \n",
       "13      4           Nice product   \n",
       "14      5               Terrific   \n",
       "15      5              Brilliant   \n",
       "16      5      Terrific purchase   \n",
       "17      5              Wonderful   \n",
       "18      5              Must buy!   \n",
       "19      5  Mind-blowing purchase   \n",
       "20      5          Great product   \n",
       "21      5      Terrific purchase   \n",
       "22      5         Simply awesome   \n",
       "23      4   Good quality product   \n",
       "24      1              Very poor   \n",
       "25      5              Fabulous!   \n",
       "26      5     Highly recommended   \n",
       "27      5  Mind-blowing purchase   \n",
       "28      5  Mind-blowing purchase   \n",
       "29      5              Wonderful   \n",
       "\n",
       "                                          Full review  \n",
       "0   The Best Phone for the MoneyThe iPhone 11 offe...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Previously I was using one plus 3t it was a gr...  \n",
       "3   Amazing Powerful and Durable Gadget.I’m am ver...  \n",
       "4   iphone 11 is a very good phone to buy only if ...  \n",
       "5   It’s a must buy who is looking for an upgrade ...  \n",
       "6   Value for money❤️❤️Its awesome mobile phone in...  \n",
       "7   This is my first iOS phone. I am very happy wi...  \n",
       "8   *Review after 10 months of usage*Doesn't seem ...  \n",
       "9   Best budget Iphone till date ❤️ go for it guys...  \n",
       "10  Excellent camera, good performance, no lag. Th...  \n",
       "11  It’s been almost a month since I have been usi...  \n",
       "12  Iphone is just awesome.. battery backup is ver...  \n",
       "13  Awesome Phone. Slightly high price but worth. ...  \n",
       "14  Really worth of money. i just love it. It is t...  \n",
       "15  I have migrated from OP 7pro... and trust me, ...  \n",
       "16  Upgraded from iphone 6 to 11 best phone for ip...  \n",
       "17  This is my first ever I phone. Before this I w...  \n",
       "18  It’s an amazing product from apple and the cam...  \n",
       "19  This will help you more. See if you are planni...  \n",
       "20  Well you all know the specifications . One of ...  \n",
       "21  The built quality is not very premium.The batt...  \n",
       "22  Really good actually this is my first apple pr...  \n",
       "23  it is very good at performance. Camera is best...  \n",
       "24  Reviewing again after 5 months. At the beginni...  \n",
       "25  I can say I'm damn impressed with iPhone 11. A...  \n",
       "26  It's my first time to use iOS phone and I am l...  \n",
       "27  Best Quality Product OF iPhone Series , Sound ...  \n",
       "28  First thanks to Flipkart for this amazing deal...  \n",
       "29  I just directly switch from iphone 6s to iphon...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame\n",
    "i_phone11_review = pd.DataFrame({\"Rating\": Rat,\n",
    "                     \"Review_summary\" : Review_summary,\n",
    "                     \"Full review\" : Full_review})\n",
    "\n",
    "i_phone11_review.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n",
    "\n",
    "Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C://Users//Friday//chromedriver.exe\")\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "driver.maximize_window()\n",
    "\n",
    "#closing the login Pop-up\n",
    "time.sleep(3)\n",
    "pop_up = driver.find_element_by_xpath(\"//div[@class='_2QfC02']/button[@class = '_2KpZ6l _2doB4z']\")\n",
    "pop_up.click()\n",
    "\n",
    "prod_ser = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']//input[@type = 'text']\")\n",
    "prod_ser.send_keys(\"sneakers\")\n",
    "\n",
    "sub_button = driver.find_element_by_xpath(\"//div[@class = 'col-12-12 _2oO9oE']//button[@class = 'L0Z3Pu']\")\n",
    "sub_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French Connection</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹799</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oxpeo</td>\n",
       "      <td>Colourblocked Trending Multicolor Ultralight c...</td>\n",
       "      <td>₹419</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SWIGGY</td>\n",
       "      <td>Casual Loafers, Sneakers Shoes for Men Pack of...</td>\n",
       "      <td>₹799</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>SM-162 Sneakers For Men</td>\n",
       "      <td>₹730</td>\n",
       "      <td>23% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bonexy</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product_Description  \\\n",
       "0   French Connection                                   Sneakers For Men   \n",
       "1               oxpeo  Colourblocked Trending Multicolor Ultralight c...   \n",
       "2              Chevit  Perfect & Affordable Combo Pack of 02 Pairs Sn...   \n",
       "3        Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "4              Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "..                ...                                                ...   \n",
       "95             SWIGGY  Casual Loafers, Sneakers Shoes for Men Pack of...   \n",
       "96          ROCKFIELD                                   Sneakers For Men   \n",
       "97              SPARX                            SM-162 Sneakers For Men   \n",
       "98          ROCKFIELD                                   Sneakers For Men   \n",
       "99             Bonexy                                   Sneakers For Men   \n",
       "\n",
       "   Price Discount  \n",
       "0   ₹799  60% off  \n",
       "1   ₹419  58% off  \n",
       "2   ₹499  72% off  \n",
       "3   ₹399  60% off  \n",
       "4   ₹474  76% off  \n",
       "..   ...      ...  \n",
       "95  ₹799  67% off  \n",
       "96  ₹499  50% off  \n",
       "97  ₹730  23% off  \n",
       "98  ₹399  60% off  \n",
       "99  ₹499  50% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting the required information and storing in the list.\n",
    "Brand = []\n",
    "Product_Description= []\n",
    "Price = []\n",
    "Discount =[]\n",
    "\n",
    "while True:\n",
    "    \n",
    "    time.sleep(3)\n",
    "        \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_2B099V']//div[@class = '_2WkVRV']\"):\n",
    "        Brand.append(i.text)\n",
    "        if len(Brand) == 100:\n",
    "            break\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_2B099V']//a\"):\n",
    "        Product_Description.append(i.get_attribute('title'))\n",
    "        if len(Product_Description) == 200:\n",
    "            break\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_25b18c']//div[@class = '_30jeq3']\"):\n",
    "        Price.append(i.text) \n",
    "        if len(Price) == 100:\n",
    "            break    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_3Ay6Sb']/span\"):\n",
    "        Discount.append(i.text)\n",
    "        if len(Discount) == 100:\n",
    "            break  \n",
    "            \n",
    "    if len(Discount) == 100:\n",
    "        break\n",
    "        \n",
    "    for j in driver.find_elements_by_xpath(\"//nav[@class ='yFHi8N']/a[@class = '_1LKTO3']\"):\n",
    "        next=[j.get_attribute(\"href\")]\n",
    "    \n",
    "    time.sleep(3)\n",
    "        \n",
    "    for n in next:\n",
    "        driver.get(n) \n",
    "    \n",
    "driver.close() \n",
    "\n",
    "Product = [] # Since Product_Description have many unwanted information am following this method to clense it.\n",
    "for i in range(0,len(Product_Description)):\n",
    "    if i == 0 or  i/2 == i//2:\n",
    "        Product.append(Product_Description[i])\n",
    "\n",
    "#Creating DataFrame.\n",
    "Flipkart_sneakers = pd.DataFrame({\"Brand\": Brand, \n",
    "                                  \"Product_Description\": Product, \n",
    "                                  \"Price\": Price , \n",
    "                                  \"Discount\": Discount})\n",
    "Flipkart_sneakers        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q9: Go to the link - https://www.myntra.com/shoes\n",
    ">>Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "Please note that applying the filter and scraping the data , everything should be done through code only and there should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C://Users//Friday//chromedriver.exe\")\n",
    "driver.get(\"https://www.myntra.com/shoes\")\n",
    "driver.maximize_window()\n",
    "\n",
    "time.sleep(3)\n",
    "#selecting black color.\n",
    "Filter2 = driver.find_elements_by_xpath(\"//li[@class ='colour-listItem']//label[@class ='common-customCheckbox']/div[@class = 'common-checkboxIndicator']\") \n",
    "Filter2[0].click()\n",
    "\n",
    "time.sleep(5)\n",
    "#setting price filter\n",
    "Filter1 = driver.find_elements_by_xpath(\"//ul[@class ='price-list']//label[@class ='common-customCheckbox vertical-filters-label']/div[@class = 'common-checkboxIndicator']\") \n",
    "Filter1[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>11470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR MAX VOLLEY Tennis</td>\n",
       "      <td>6965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Fuse Training Sports Shoes</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR MAX INFINITY 2 Sneaker</td>\n",
       "      <td>7050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity Running</td>\n",
       "      <td>12396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Solid Leather Wedges</td>\n",
       "      <td>9490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Solid Wedges</td>\n",
       "      <td>8490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Leather Solid Pumps</td>\n",
       "      <td>11990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Slip-On Sneakers</td>\n",
       "      <td>8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Leather Block Heels</td>\n",
       "      <td>9990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand                     description  price\n",
       "0   Nike      Men AIR ZOOM Running Shoes  11470\n",
       "1   Nike       Men AIR MAX VOLLEY Tennis   6965\n",
       "2   Puma  Men Fuse Training Sports Shoes   7999\n",
       "3   Nike  Men AIR MAX INFINITY 2 Sneaker   7050\n",
       "4   Nike      Men React Infinity Running  12396\n",
       "..   ...                             ...    ...\n",
       "95  Geox            Solid Leather Wedges   9490\n",
       "96  Geox              Women Solid Wedges   8490\n",
       "97  Geox       Women Leather Solid Pumps  11990\n",
       "98  Geox          Women Slip-On Sneakers   8499\n",
       "99  Geox       Women Leather Block Heels   9990\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brand,description,price = [], [], []\n",
    "q = 0\n",
    "\n",
    "while q<2:\n",
    "    time.sleep(3)\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= 'product-productMetaInfo']//h3[@class = 'product-brand']\"):\n",
    "        Brand.append(i.text)\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= 'product-productMetaInfo']//h4[@class = 'product-product']\"):\n",
    "        description.append(i.text)\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= 'product-productMetaInfo']//div[@class = 'product-price']\"):\n",
    "        price.append(i.text)\n",
    "    \n",
    "    nxt = driver.find_element_by_xpath(\"//a[@rel = 'next']\")\n",
    "    nxt.click()\n",
    "    q +=1\n",
    "\n",
    "driver.close()     \n",
    "price= [i.split('Rs. ')[1] for i in price]   \n",
    "\n",
    "myntra_blackshoes = pd.DataFrame({\"Brand\":Brand,\"description\":description,\"price\":price})\n",
    "myntra_blackshoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q10: Go to webpage https://www.amazon.in/\n",
    ">>Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "\n",
    ">After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C://Users//Friday//chromedriver.exe\")\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "driver.maximize_window()\n",
    "\n",
    "search_Box = driver.find_element_by_xpath(\"//div[@class = 'nav-search-field ']/input[@type='text']\")\n",
    "search_Box.send_keys(\"Laptop\")\n",
    "search_btn = driver.find_element_by_xpath(\"//input[@id= 'nav-search-submit-button']\")\n",
    "search_btn.click()\n",
    "\n",
    "fltr_btn = driver.find_elements_by_xpath(\"//ul[@aria-labelledby= 'p_n_feature_thirteen_browse-bin-title']//div[@class= 'a-checkbox a-checkbox-fancy s-navigation-checkbox aok-float-left']\")\n",
    "fltr_btn[-3].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record(item):\n",
    "    \"\"\"Extract and return the Data from a Single record\"\"\"\n",
    "    \n",
    "    #Description\n",
    "    atag = item.h2.a\n",
    "    description = atag.text.strip()\n",
    "    \n",
    "    try:\n",
    "        #Price\n",
    "        price_parent = item.find('span', 'a-price')\n",
    "        price = price_parent.find('span', 'a-offscreen').text\n",
    "    except AttributeError: #Attribute error handeling\n",
    "        price = ''\n",
    "    \n",
    "    try:\n",
    "        #Rating\n",
    "        rating = item.i.text\n",
    "    except AttributeError: #Attribute error handeling\n",
    "        rating = ''\n",
    "        \n",
    "        \n",
    "    result = (description, price, rating)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...</td>\n",
       "      <td></td>\n",
       "      <td>₹35,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>₹83,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP 14 Thin &amp; Light 14-inch FHD Laptop (11th Ge...</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>₹76,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>₹38,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>53962.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>2.7 out of 5 stars</td>\n",
       "      <td>₹1,98,590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>₹1,35,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>₹39,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion Gaming 11th Gen Intel Core i7 Proc...</td>\n",
       "      <td></td>\n",
       "      <td>₹83,128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...                       \n",
       "1  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...  5.0 out of 5 stars   \n",
       "2  HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...  4.6 out of 5 stars   \n",
       "3  (Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...  1.0 out of 5 stars   \n",
       "4  Mi Notebook Horizon Edition 14 Intel Core i5-1...  4.3 out of 5 stars   \n",
       "5  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...  2.7 out of 5 stars   \n",
       "6  Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...  4.3 out of 5 stars   \n",
       "7  LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...  3.5 out of 5 stars   \n",
       "8  HP Pavilion Gaming 11th Gen Intel Core i7 Proc...                       \n",
       "9  Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...  4.3 out of 5 stars   \n",
       "\n",
       "       Price  \n",
       "0    ₹35,990  \n",
       "1    ₹83,990  \n",
       "2    ₹76,500  \n",
       "3    ₹38,990  \n",
       "4   53962.00  \n",
       "5  ₹1,98,590  \n",
       "6  ₹1,35,490  \n",
       "7    ₹39,990  \n",
       "8    ₹83,128  \n",
       "9             "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = []\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "results = soup.find_all('div',{'data-component-type' : 's-search-result'})\n",
    "\n",
    "for item in results:\n",
    "    record = extract_record(item)\n",
    "    if record:\n",
    "        records.append(record)\n",
    "        \n",
    "records = records[:10]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "title =[]\n",
    "Ratings =[]\n",
    "Price =[]\n",
    "\n",
    "for i in records:\n",
    "    title.append(i[0])\n",
    "    Ratings.append(i[2])\n",
    "    Price.append(i[1])\n",
    "    \n",
    "intel_core_i7_amazon = pd.DataFrame({\"Title\":title,\"Ratings\":Ratings,\"Price\":Price})\n",
    "intel_core_i7_amazon            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS ROG G703GI-E5148T 17.3-inch FHD 144Hz/3ms...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>₹5,22,077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell XPS 9570 15.6-inch UHD Laptop (8th Gen i9...</td>\n",
       "      <td>2.3 out of 5 stars</td>\n",
       "      <td>₹2,27,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "      <td>₹2,59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Omen X 2S Core i9 9th Gen 15.6-inch Dual Sc...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>₹3,64,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell Alienware 17 Area 51 9thGeneration Corei9...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) Dell G7 15 Gaming 7588 Laptop Intel ...</td>\n",
       "      <td></td>\n",
       "      <td>₹1,14,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS ROG Strix Scar 15 (2020), 15.6\" FHD 300Hz...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>₹2,14,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch UHD Gaming La...</td>\n",
       "      <td>2.7 out of 5 stars</td>\n",
       "      <td>₹3,42,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS ZenBook Pro Duo UX581 Intel Core i9 9th G...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>₹2,69,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell G7 7500 15.6inch FHD 300 Hz Display Gamin...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>₹2,06,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  ASUS ROG G703GI-E5148T 17.3-inch FHD 144Hz/3ms...  3.9 out of 5 stars   \n",
       "1  Dell XPS 9570 15.6-inch UHD Laptop (8th Gen i9...  2.3 out of 5 stars   \n",
       "2  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  3.3 out of 5 stars   \n",
       "3  HP Omen X 2S Core i9 9th Gen 15.6-inch Dual Sc...  4.4 out of 5 stars   \n",
       "4  Dell Alienware 17 Area 51 9thGeneration Corei9...  4.2 out of 5 stars   \n",
       "5  (Renewed) Dell G7 15 Gaming 7588 Laptop Intel ...                       \n",
       "6  ASUS ROG Strix Scar 15 (2020), 15.6\" FHD 300Hz...  1.0 out of 5 stars   \n",
       "7  Dell Alienware m15(R3) 15.6-inch UHD Gaming La...  2.7 out of 5 stars   \n",
       "8  ASUS ZenBook Pro Duo UX581 Intel Core i9 9th G...  4.0 out of 5 stars   \n",
       "9  Dell G7 7500 15.6inch FHD 300 Hz Display Gamin...  5.0 out of 5 stars   \n",
       "\n",
       "       Price  \n",
       "0  ₹5,22,077  \n",
       "1  ₹2,27,200  \n",
       "2  ₹2,59,990  \n",
       "3  ₹3,64,800  \n",
       "4             \n",
       "5  ₹1,14,490  \n",
       "6  ₹2,14,990  \n",
       "7  ₹3,42,990  \n",
       "8  ₹2,69,990  \n",
       "9  ₹2,06,990  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C://Users//Friday//chromedriver.exe\")\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "driver.maximize_window()\n",
    "\n",
    "search_Box = driver.find_element_by_xpath(\"//div[@class = 'nav-search-field ']/input[@type='text']\")\n",
    "search_Box.send_keys(\"Laptop\")\n",
    "search_btn = driver.find_element_by_xpath(\"//input[@id= 'nav-search-submit-button']\")\n",
    "search_btn.click()\n",
    "\n",
    "fltr_btn = driver.find_elements_by_xpath(\"//ul[@aria-labelledby= 'p_n_feature_thirteen_browse-bin-title']//div[@class= 'a-checkbox a-checkbox-fancy s-navigation-checkbox aok-float-left']\")\n",
    "fltr_btn[-2].click()\n",
    "\n",
    "def extract_record(item):\n",
    "    \"\"\"Extract and return the Data from a Single record\"\"\"\n",
    "    \n",
    "    #Description\n",
    "    atag = item.h2.a\n",
    "    description = atag.text.strip()\n",
    "    \n",
    "    try:\n",
    "        #Price\n",
    "        price_parent = item.find('span', 'a-price')\n",
    "        price = price_parent.find('span', 'a-offscreen').text\n",
    "    except AttributeError: #Attribute error handeling\n",
    "        price = ''\n",
    "    \n",
    "    try:\n",
    "        #Rating\n",
    "        rating = item.i.text\n",
    "    except AttributeError: #Attribute error handeling\n",
    "        rating = ''\n",
    "        \n",
    "        \n",
    "    result = (description, price, rating)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "records = []\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "results = soup.find_all('div',{'data-component-type' : 's-search-result'})\n",
    "\n",
    "for item in results:\n",
    "    record = extract_record(item)\n",
    "    if record:\n",
    "        records.append(record)\n",
    "        \n",
    "records = records[:10]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "title =[]\n",
    "Ratings =[]\n",
    "Price =[]\n",
    "\n",
    "for i in records:\n",
    "    title.append(i[0])\n",
    "    Ratings.append(i[2])\n",
    "    Price.append(i[1])\n",
    "    \n",
    "intel_core_i9_amazon = pd.DataFrame({\"Title\":title,\"Ratings\":Ratings,\"Price\":Price})\n",
    "intel_core_i9_amazon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
